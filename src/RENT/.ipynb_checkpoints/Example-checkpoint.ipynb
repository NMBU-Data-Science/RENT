{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RENT applied to a binary classification problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Jupyter notebook illustrates how to apply RENT to your data for feature selection with a *binary classification* problem. This Jupyter notebook is complimentary to the manscript published at arXiv.org.\n",
    "\n",
    "[RENT -- Repeated Elastic Net Technique for Feature Selection](https://arxiv.org/abs/2009.12780)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For an example on how to use RENT for feature selection on a regression problem, please have a look here [insert link when ready]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [Generate data for a binary classification problem](#Generate-data-for-a-binary-classification-problem)\n",
    "2. [Run RENT](#Run-RENT)\n",
    "3. [Extract feature selection stability information from weight distributions](#Extract-feature-selection-stability-information-from-weight-distributions)\n",
    "4. [Make predictions with selected features](#Make-predictions-with-selected-features)\n",
    "5. [Check whether results are better than random selection from full set of features](#Check-whether-results-are-better-than-random-selection-from-full-set-of-features)\n",
    "6. [Plot confusion - variance plot](#Plot-confusion---variance-plot)\n",
    "7. [Check robustness of label prediction for specific objects](#Check-robustness-of-label-prediction-for-specific-objects)\n",
    "8. [Optional - if you want to save time by reducing number of computations](#Optional---if-you-want-to-save-time-by-reducing-number-of-computations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate data for a binary classification problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let us generate a dataset with scikit-learn's `make_classification`. The dataset is then split into a train (data, labels) and a test (test_data, test_labels) dataset with corresponding labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Make example data for binary classification\n",
    "data = make_classification(n_samples=250, n_features=100, n_informative=20, n_redundant=10, random_state=0, shuffle=False)\n",
    "\n",
    "# Insert data into a pandas dataframe\n",
    "my_data = pd.DataFrame(data[0])\n",
    "my_target = data[1]\n",
    "my_feat_names = ['f{0}'.format(x+1) for x in range(len(my_data.columns))]\n",
    "\n",
    "# Split data into training and test data using scikit-learn\n",
    "data, test_data, labels, test_labels = train_test_split(my_data, my_target, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have quick look at the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>-2.781523</td>\n",
       "      <td>1.668790</td>\n",
       "      <td>-1.092144</td>\n",
       "      <td>-1.654628</td>\n",
       "      <td>2.431091</td>\n",
       "      <td>-0.934767</td>\n",
       "      <td>1.236988</td>\n",
       "      <td>2.707152</td>\n",
       "      <td>-1.353128</td>\n",
       "      <td>0.256712</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.011332</td>\n",
       "      <td>-0.047554</td>\n",
       "      <td>-1.986357</td>\n",
       "      <td>-0.089812</td>\n",
       "      <td>0.872148</td>\n",
       "      <td>0.668392</td>\n",
       "      <td>1.509412</td>\n",
       "      <td>-0.567483</td>\n",
       "      <td>-0.272206</td>\n",
       "      <td>1.154505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>-0.319027</td>\n",
       "      <td>-1.582700</td>\n",
       "      <td>-2.530228</td>\n",
       "      <td>3.790455</td>\n",
       "      <td>-1.443424</td>\n",
       "      <td>6.198178</td>\n",
       "      <td>-3.841906</td>\n",
       "      <td>1.752765</td>\n",
       "      <td>-3.137109</td>\n",
       "      <td>2.196795</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.251673</td>\n",
       "      <td>-1.543028</td>\n",
       "      <td>1.669943</td>\n",
       "      <td>-0.211913</td>\n",
       "      <td>-0.381762</td>\n",
       "      <td>0.393836</td>\n",
       "      <td>2.391554</td>\n",
       "      <td>-1.078529</td>\n",
       "      <td>1.383302</td>\n",
       "      <td>-0.571235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.561952</td>\n",
       "      <td>6.538859</td>\n",
       "      <td>-2.159691</td>\n",
       "      <td>-2.692623</td>\n",
       "      <td>-3.958765</td>\n",
       "      <td>-4.349420</td>\n",
       "      <td>1.881853</td>\n",
       "      <td>2.022534</td>\n",
       "      <td>-1.494595</td>\n",
       "      <td>0.409014</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.027384</td>\n",
       "      <td>0.764850</td>\n",
       "      <td>-0.831727</td>\n",
       "      <td>-1.410857</td>\n",
       "      <td>-1.798279</td>\n",
       "      <td>-0.698159</td>\n",
       "      <td>0.606902</td>\n",
       "      <td>0.850187</td>\n",
       "      <td>-0.850901</td>\n",
       "      <td>0.438367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>-0.629430</td>\n",
       "      <td>-3.191968</td>\n",
       "      <td>-0.681880</td>\n",
       "      <td>6.868408</td>\n",
       "      <td>1.582777</td>\n",
       "      <td>3.321997</td>\n",
       "      <td>-3.044179</td>\n",
       "      <td>-0.122689</td>\n",
       "      <td>1.127910</td>\n",
       "      <td>4.523192</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.521608</td>\n",
       "      <td>0.622348</td>\n",
       "      <td>-0.483599</td>\n",
       "      <td>0.032395</td>\n",
       "      <td>0.133245</td>\n",
       "      <td>-0.611717</td>\n",
       "      <td>1.282187</td>\n",
       "      <td>0.682978</td>\n",
       "      <td>1.795284</td>\n",
       "      <td>1.473537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>5.271039</td>\n",
       "      <td>-0.122686</td>\n",
       "      <td>0.150363</td>\n",
       "      <td>-0.411842</td>\n",
       "      <td>-1.917968</td>\n",
       "      <td>-3.851898</td>\n",
       "      <td>2.398042</td>\n",
       "      <td>-0.106560</td>\n",
       "      <td>3.216194</td>\n",
       "      <td>1.897365</td>\n",
       "      <td>...</td>\n",
       "      <td>2.125387</td>\n",
       "      <td>-0.050687</td>\n",
       "      <td>0.401114</td>\n",
       "      <td>0.788210</td>\n",
       "      <td>-0.616034</td>\n",
       "      <td>-1.264740</td>\n",
       "      <td>-0.236318</td>\n",
       "      <td>-1.572748</td>\n",
       "      <td>-0.053176</td>\n",
       "      <td>-0.514468</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6   \\\n",
       "106 -2.781523  1.668790 -1.092144 -1.654628  2.431091 -0.934767  1.236988   \n",
       "243 -0.319027 -1.582700 -2.530228  3.790455 -1.443424  6.198178 -3.841906   \n",
       "4    2.561952  6.538859 -2.159691 -2.692623 -3.958765 -4.349420  1.881853   \n",
       "219 -0.629430 -3.191968 -0.681880  6.868408  1.582777  3.321997 -3.044179   \n",
       "61   5.271039 -0.122686  0.150363 -0.411842 -1.917968 -3.851898  2.398042   \n",
       "\n",
       "           7         8         9   ...        90        91        92  \\\n",
       "106  2.707152 -1.353128  0.256712  ... -1.011332 -0.047554 -1.986357   \n",
       "243  1.752765 -3.137109  2.196795  ... -1.251673 -1.543028  1.669943   \n",
       "4    2.022534 -1.494595  0.409014  ... -0.027384  0.764850 -0.831727   \n",
       "219 -0.122689  1.127910  4.523192  ... -0.521608  0.622348 -0.483599   \n",
       "61  -0.106560  3.216194  1.897365  ...  2.125387 -0.050687  0.401114   \n",
       "\n",
       "           93        94        95        96        97        98        99  \n",
       "106 -0.089812  0.872148  0.668392  1.509412 -0.567483 -0.272206  1.154505  \n",
       "243 -0.211913 -0.381762  0.393836  2.391554 -1.078529  1.383302 -0.571235  \n",
       "4   -1.410857 -1.798279 -0.698159  0.606902  0.850187 -0.850901  0.438367  \n",
       "219  0.032395  0.133245 -0.611717  1.282187  0.682978  1.795284  1.473537  \n",
       "61   0.788210 -0.616034 -1.264740 -0.236318 -1.572748 -0.053176 -0.514468  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run RENT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RENT offers different settings which are described in the RENT_parallel file. The setting here is the standard setting used in our paper with fewer **train-test-splits** (faster computation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'num_tt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-7f50ee360ff1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m# Apply RENT to your training data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m analysis = fs.RENT(data=data, \n\u001b[0m\u001b[0;32m     12\u001b[0m                    \u001b[0mtarget\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m                    \u001b[0mfeat_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'num_tt'"
     ]
    }
   ],
   "source": [
    "# Import RENT for computation accross multiple cores\n",
    "import RENT_parallel as fs\n",
    "\n",
    "# Define a range of regularisation parameters C for elastic net. A minimum of at least one value is required.\n",
    "my_C_params = [0.1, 1, 10]\n",
    "\n",
    "# Define a reange of l1-ratios for elastic net.  A minimum of at least one value is required.\n",
    "my_l1_ratios = [0, 0.1, 0.25, 0.5, 0.75, 0.9, 1]\n",
    "\n",
    "# Apply RENT to your training data\n",
    "analysis = fs.RENT(data=data, \n",
    "                   target=labels,\n",
    "                   feat_names=data.columns,\n",
    "                   C=my_C_params,\n",
    "                   poly='OFF', \n",
    "                   scoring='f1',\n",
    "                   method='logreg',\n",
    "                   testsize_range=(0.25, 0.25),\n",
    "                   K=50, \n",
    "                   l1_ratios = my_l1_ratios,\n",
    "                   verbose = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it is time to determine the stability of selection of each feature in the training data. The command below will extract useful information from the distribution of weights (based on `num_tt`, the number of train-test-splits or number of models in the ensemble) seperately for each feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyse distribution of feature weights across `num_tt` models. \n",
    "analysis.run_analysis()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can take a closer look into different calculations from RENT. The scores dataframe shows the average prediction scores with the defined scoring measure (set in RENT) for a given combination of l1_ratios (rows) and C parameters (columns), over the different models in RENT (`num_tt` represents the number of models). The structure for zeroes is the same - here we show the percentage of variables set to 0 for a parameter combination over the models in RENT. \n",
    "**scores** and **zeroes** are both important as we want to reach a high score but also reduce the feature set size simultaneously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = analysis.get_scores_summary_by_regParam()\n",
    "pd.DataFrame(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zeroes = analysis.get_average_zero_features()\n",
    "pd.DataFrame(zeroes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find the best combination, we norm **scores** and **zeroes** to bring them on a comparable scale. Then, with the harmonic mean of the two matrices, we build a new matrix called **combi** where we now take the parameter combination with the highest value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "normed_scores = (scores-np.nanmin(scores.values))/(np.nanmax(scores.values)-np.nanmin(scores.values))\n",
    "normed_zeroes = (zeroes-np.nanmin(zeroes.values))/(np.nanmax(zeroes.values)-np.nanmin(zeroes.values))\n",
    "normed_zeroes = normed_zeroes.astype(\"float\")\n",
    "\n",
    "combi = (normed_scores ** - 1 + normed_zeroes ** - 1) ** - 1\n",
    "pd.DataFrame(combi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the combination matrix we see that the combination C = 0.1, l1_ratio = 1.0 has the highest value. We will use it now as the **best** parameter combination and come to the actual feature selection step where we select features based on three quality criteria **tau_1**, **tau_2** and **tau_3** (more info in the paper). With the function **get_spec_weights_summary** we get a summary dataframe which shows us the values for the quality criteria for each feature, the actual reduced dataset with **only** important features remaining and an array of the positions of the selected features in the columns of the original dataframe.\n",
    "\n",
    "The plot below shows the absolute count for each feature, i.e. how often it is assigned a value not equal to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_combi_row, best_combi_col  = np.where(combi == np.nanmax(combi.values))\n",
    "l1_ratio = combi.index[np.nanmax(best_combi_row)]\n",
    "C = combi.columns[np.nanmin(best_combi_col)]\n",
    "print(\"C: \", C, \"l1_ratio: \", l1_ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract feature selection stability information from weight distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_spec_weights, sel_feat_df, features = analysis.get_spec_weights_summary(C=C, \n",
    "                                                                                l1_ratio=l1_ratio, \n",
    "                                                                                tau_1=0.9, \n",
    "                                                                                tau_2=0.9, \n",
    "                                                                                tau_3=0.975)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary specific weight shows the summary statistics for each feature\n",
    "summary_spec_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sel_feat_df contains the selected features\n",
    "sel_feat_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to evaluate the predictive power of the selected features. Therefore, we reduce the train and test datasets to the selected features and build a machine learning model. Here, we use a Logistic Regression model without any penalty but you are free to use other learning algorithms, as well. Test scores are evaluated with different measures (**f1**, **accuarcy**, **matthews correlation coefficient**) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make predictions with selected features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict test set\n",
    "\n",
    "# Import what is needed for prediction and evaluation of predictions from test set\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, matthews_corrcoef, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression as LR\n",
    "\n",
    "# Scale the data accordingly\n",
    "sc = StandardScaler()\n",
    "train_data_1 = sc.fit_transform(data.loc[:, sel_feat_df.columns])\n",
    "test_data_1 = sc.transform(test_data.loc[:, sel_feat_df.columns])\n",
    "\n",
    "# Train model with \n",
    "model = LR(penalty='none', max_iter=8000, solver=\"saga\", random_state=0).\\\n",
    "        fit(train_data_1, labels)\n",
    "\n",
    "# Print results\n",
    "print(\"All features f1 1: \", f1_score(test_labels, model.predict(test_data_1)))\n",
    "print(\"All features f1 0: \", f1_score(1 - test_labels, 1 - model.predict(test_data_1)))\n",
    "print(\"All features acc: \", accuracy_score(test_labels, model.predict(test_data_1)))\n",
    "print(\"All features matthews: \", matthews_corrcoef(test_labels, model.predict(test_data_1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a feasibility study we can evaluate how useful feature selection is at all on the dataset (permutation of the test labels), and if the RENT features are relevant or if it is not relevant which features are used to train a model (random feature drawing)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check whether results are better than random selection from full set of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis.feasibility_study(test_data=test_data, \n",
    "                           test_labels=test_labels, \n",
    "                           feature_size= len(sel_feat_df.columns), \n",
    "                           features=sel_feat_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Besides the feature selection RENT has the property of summarizing the predictive behavior of single samples. Before we can generate histogram plots for them we need to check how often they were classified incorrectly. For each patient the following table shows how often a the patient has been part of a test set within RENT, which class his true class is, how often he has not been predicted correctly and the corresponding percentage of incorrect prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect correctness of class label predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inc = analysis.get_spec_incorr_lables(C=0.1, l1_ratio=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot confusion - variance plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next plot is based on a PCA plot on the incorrect predictions and shows a mapping of the patients about the level of incorrectness. Patiens who were incorrect in less than **25%** are the true positive/negative and those above **75%** incorrectness were the false positive/negative. The patients between are the neutral ones, correspondingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis.confusion_variance_plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check robustness of label prediction for specific objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With histogram plots we can demonstrate the predictions for single objects in a logistic regression model over the different RENT models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "analysis.pred_proba()\n",
    "analysis.pred_proba_plot(C=0.1, l1_ratio=1, object_id=[1,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional - if you want to save time by reducing number of computations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RENT can be computationally expensive, since it will compute many ensembles of models when given multiple values for regularisation paramter `C` and `l1_ratio` for elastic net regularised models. The total number of ensembles of models is `C` * `l1_ratio`, which is why identifying the best performing combination of `C` and `l1_ratio` before applying RENT will save you a considerable amount of time. To realise the time gain you then input only the best performing combination of parameters `C` and `l1_ratios` in RENT, not a range of values. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you play around with RENT and use it the first time, just ignore the next code cell.\n",
    "\n",
    "It is important to remember that the paramter `C` is responsible for the regularization strength in scikit-learn and that it is the inverse regularisation strength parameter lambda as typically defined in textbooks. This can be important to know when you want to further interpret results etc. Furthermore, parameter `l1_ratio` defines the Elastic Net mixing parameter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import parameter_selection as ps #\n",
    "import warnings\n",
    "\n",
    "# Activate this to not show all the convergence warnings.\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Define ranges for C and l1_ratios\n",
    "my_reg_params = [0.1, 1, 10] # C\n",
    "my_l1_params = [0, 0.1, 0.25, 0.5, 0.75, 0.9, 1] # l1_ratio\n",
    "testsize_range = (0.25, 0.25) # Define upper and lower random size of test sets. Use same value left and right in tuple to keep test size constant.\n",
    "\n",
    "best_C, best_l1_ratio = ps.parameter_selection(data=data, \n",
    "                                               labels=labels, \n",
    "                                               C_params=my_reg_params, \n",
    "                                               l1_params=my_l1_params,\n",
    "                                               n_splits=5, \n",
    "                                               testsize_range = testsize_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ps.parameter_selection` returns `C` and `l1_ratio` for best performing model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"suggested C: \", best_C)\n",
    "print(\"suggested l1_ratio: \", best_l1_ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**suggested C** and **suggested l1_ratio** would be the suggested parameter combination to select for this dataset (based on the procedure above). As stated before, this is not necessary but you can select own parameters you would like to try RENT with, directly in the RENT class. RENT delivers then the best paramter combination found. The process above is useful for speeding up the whole procedure because then, RENT is run only with one parameter combination. For the fundamental application of RENT see the next cell."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
