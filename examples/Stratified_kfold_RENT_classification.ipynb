{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "import numpy as np\n",
    "from RENT import RENT\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression as LR\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, matthews_corrcoef\n",
    "\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "wisconsin = load_breast_cancer()\n",
    "data = pd.DataFrame(wisconsin.data)\n",
    "target = wisconsin.target\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "original_train_data, original_test_data, original_train_labels, original_test_labels = \\\n",
    "train_test_split(data, target, random_state=0, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = True \n",
    "counter = 0\n",
    "max_counts = 1\n",
    "rs = 0\n",
    "n_folds = 5\n",
    "\n",
    "my_data = original_train_data.copy()\n",
    "my_target = pd.DataFrame(original_train_labels.copy()) # must be DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'parameter_selection'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-6ef09ce77ae6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     55\u001b[0m                                                        \u001b[0mK\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m                                                        \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'logreg'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m                                                        verbose=1)\n\u001b[0m\u001b[0;32m     58\u001b[0m                 \u001b[0manalysis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'parameter_selection'"
     ]
    }
   ],
   "source": [
    "# run RENT until counter reaches max_counts\n",
    "\n",
    "while run==True:\n",
    "    counter += 1\n",
    "    # k-fold splits\n",
    "    skf = StratifiedKFold(n_splits=n_folds, random_state = rs, shuffle=True)\n",
    "    \n",
    "    #for next RENT-run (if counter != max_count, use another random state to split the data)\n",
    "    rs += 1\n",
    "    \n",
    "    # C and l1 and testsize-range parameters to try \n",
    "    my_C_params = [0.1, 1, 10]\n",
    "    my_l1_params = [0.1, 0.5, 0.9]\n",
    "    testsize_range = (0.25, 0.25)\n",
    "    \n",
    "    # store prediction scores of train and test data for each split in dataframe (end with a list of dataframes)\n",
    "    fs_scores = list()\n",
    "    for s in range(skf.get_n_splits()):\n",
    "        fs_scores.append(pd.DataFrame(index=my_l1_params, columns=my_C_params))\n",
    "    scores_pred = list()\n",
    "    for s in range(skf.get_n_splits()):\n",
    "        scores_pred.append(pd.DataFrame(index=my_l1_params, columns=my_C_params))\n",
    "    \n",
    "    # define all dicts where we want to store results\n",
    "    incorrect_labels_dict = {}\n",
    "    incorr_avg = {}\n",
    "    incorr_max = {}\n",
    "    incorr_min = {}\n",
    "    count_features = {}\n",
    "    union_features = {}\n",
    "    intersection_features = {}\n",
    "    score_prediction = {}\n",
    "    models = {}\n",
    "    \n",
    "    # now we perform RENT feature selection\n",
    "    for C in my_C_params:\n",
    "        for l1 in my_l1_params:\n",
    "            i = 0 # counter \n",
    "            \n",
    "            incorr_labels, mod, scores, features = [], [], [], []\n",
    "            df = pd.DataFrame(index=my_data.index)\n",
    "            \n",
    "            for train, test in skf.split(my_data, my_target):\n",
    "                train_data = my_data.iloc[train,:]\n",
    "                train_target = my_target.iloc[train,:]\n",
    "                \n",
    "                analysis = RENT.RENT_Classification(data=train_data,\n",
    "                                                       target=train_target.iloc[:,0],\n",
    "                                                       feat_names=train_data.columns,\n",
    "                                                       C=[C],\n",
    "                                                       l1_ratios=[l1],\n",
    "                                                       parameter_selection=False,\n",
    "                                                       poly='OFF',\n",
    "                                                       testsize_range=testsize_range,\n",
    "                                                       K=100,\n",
    "                                                       method='logreg',\n",
    "                                                       verbose=1)\n",
    "                analysis.train()\n",
    "                \n",
    "                # perform feature selection\n",
    "                sel_features = analysis.selectFeatures(tau_1=0.9, tau_2=0.9, tau_3=0.975)\n",
    "                \n",
    "                # store incorrect predictions\n",
    "                incorrectness = analysis.summary_objects()\n",
    "                \n",
    "                # predict on test set to get prediction scores thereof\n",
    "                sc = StandardScaler()\n",
    "                train_sample = sc.fit_transform(train_data.iloc[:,sel_features])\n",
    "                test_sample = sc.transform(my_data.iloc[test,sel_features])\n",
    "                \n",
    "                model = LR(penalty='none', max_iter=8000, solver='saga').fit(train_sample, train_target)\n",
    "                score = matthews_corrcoef(my_target.iloc[test,:], model.predict(test_sample))\n",
    "                \n",
    "                # store results\n",
    "                scores.append(score)\n",
    "                mod.append(model)\n",
    "                features.append(sel_features)\n",
    "                incorr_labels.append(incorrectness.iloc[:,-1])\n",
    "                \n",
    "                df = pd.concat([df,incorrectness.iloc[:,-1]], axis=1)\n",
    "                \n",
    "                score_mat = analysis.get_enetParam_matrices()[0]\n",
    "                \n",
    "                fs_scores[i].loc[l1,C] = score_mat.values[0]\n",
    "                scores_pred[i].loc[l1,C] = score\n",
    "                \n",
    "                i += 1\n",
    "                \n",
    "            # fill the dictionaries\n",
    "            \n",
    "            df.columns = ['fold{0}'.format(x+1) for x in range(skf.get_n_splits())]\n",
    "            incorrect_labels_dict[(l1,C)] = df\n",
    "            score_prediction[(l1,C)] = scores\n",
    "            models[(l1,C)] = mod\n",
    "            \n",
    "            features_set = []\n",
    "            for f in features:\n",
    "                features_set.append(set(f))\n",
    "                \n",
    "            #union and intersection of all features across the k folds\n",
    "            features_union = list(set.union(*features_set))\n",
    "            features_intersection = list(set.intersection(*features_set)) \n",
    "            \n",
    "            # count how often each feature was selected across the k folds (0 to k)\n",
    "            features_count = pd.Series(0, index=features_union)\n",
    "            for f in features:\n",
    "                features_count.loc[f] += 1\n",
    "            \n",
    "            union_features[(l1,C)] = features_union\n",
    "            intersection_features[(l1,C)] = features_intersection\n",
    "            count_features[(l1,C)] = features_count\n",
    "            \n",
    "            # store average, maximal and minimal  incor. predicitons\n",
    "            incorr_labels_avg = pd.DataFrame(np.round(list(np.apply_along_axis(np.nanmean,1,df))),\\\n",
    "                         index=my_data.index)\n",
    "            incorr_labels_avg.columns = [\"nr incorr\"]\n",
    "\n",
    "            incorr_labels_max = pd.DataFrame(list(np.apply_along_axis(np.nanmax,1,df)),\\\n",
    "                         index=my_data.index)\n",
    "            incorr_labels_max.columns = [\"nr incorr\"]\n",
    "            \n",
    "            incorr_labels_min = pd.DataFrame(list(np.apply_along_axis(np.nanmin,1,df)),\\\n",
    "                         index=my_data.index)\n",
    "            incorr_labels_min.columns = [\"nr incorr\"]\n",
    "            \n",
    "            \n",
    "            incorr_avg[(l1,C)] = incorr_labels_avg\n",
    "            incorr_max[(l1,C)] = incorr_labels_max\n",
    "            incorr_min[(l1,C)] = incorr_labels_min\n",
    "\n",
    "            \n",
    "            \n",
    "    # now find the best l1 and C\n",
    "    mat_pred = pd.DataFrame(0, index=my_l1_params, columns=my_C_params)\n",
    "    for s in scores_pred:\n",
    "        mat_pred = mat_pred + s\n",
    "    mat_pred = mat_pred/len(scores_pred)\n",
    "\n",
    "    mat_train = pd.DataFrame(0, index=my_l1_params, columns=my_C_params)\n",
    "    for s in fs_scores:\n",
    "        mat_train = mat_train + s\n",
    "    mat_train = mat_train/len(fs_scores)\n",
    "\n",
    "    best_row, best_col  =np.where(mat_pred == np.max(mat_pred.values))\n",
    "    best_l1 = mat_pred.index[np.max(best_row)]\n",
    "    best_C = mat_pred.columns[np.min(best_col)]     \n",
    "   \n",
    "    run=False # we stop after one run... additional code could be added to run multiple times. Then we would need to \n",
    "    # store the reduced data matrix and rerun it\n",
    "    # fs_data = my_data.loc[:, union_features[(best_l1,best_C)]]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for the best parameter combination: incorrect prediction % across all folds\n",
    "incorrect_labels_dict[(best_l1, best_C)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average prediction error over all folds\n",
    "incorr_avg[(best_l1, best_C)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count how often a feature was selected through the k folds (left column:feature, right column:count)\n",
    "count_features[(best_l1, best_C)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features that were selected in at least one fold (all with count >=1)\n",
    "union_features[(best_l1, best_C)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# intersection of selected features ( all features with count k - selected in each fold)\n",
    "intersection_features[(best_l1, best_C)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
