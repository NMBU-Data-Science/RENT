{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RENT applied to a binary classification problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Jupyter notebook illustrates how to apply RENT to your data for feature selection with a *binary classification* problem. It is also complimentary to the manscript published at arXiv.org.\n",
    "\n",
    "[RENT -- Repeated Elastic Net Technique for Feature Selection](https://arxiv.org/abs/2009.12780)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For an example on how to use RENT for feature selection on a **regression problem**, please have a look this [Jupyter Notebook](https://github.com/NMBU-Data-Science/RENT/blob/master/src/RENT/Regression_example.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [Load Wisconsin Breast Cancer dataset](#Load-Wisconsin-Breast-Cancer-dataset)\n",
    "2. [Define RENT ensemble for binary classification](#Define-RENT-ensemble-for-binary-classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First import needed modulse and apply some settings to the Jupyter notebook for better visualisation of results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', 2000)\n",
    "import RENT\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Wisconsin Breast Cancer dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now load the data from sciki-learn, store it in a pandas DataFrame and split it into a training and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "wisconsin = load_breast_cancer()\n",
    "data = pd.DataFrame(wisconsin.data)\n",
    "target = wisconsin.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(data, target, random_state=0, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define RENT ensemble for binary classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The main idea**\n",
    "\n",
    "Using the RENT approach we will train an **ensemble of unique models** based on **unique subsets** of the training data. Since each model is trained on a unique subset of the training data, all models will be slightly different from each other and elastic net regularisation **may select different features for each model**. \n",
    "\n",
    "We investigate **how consistenly elastic net selects features** across all unique models by analysing distributions of the weight sizes of each feature. Using specific criteria $\\tau_1$, $\\tau_2$ and $\\tau_3$ applied to those weight size distributions, we can regulate how aggressively RENT will select features from the full set of features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a range of regularisation parameters C for elastic net. A minimum of at least one value is required.\n",
    "my_C_params = [0.1, 1, 10]\n",
    "\n",
    "# Define a reange of l1-ratios for elastic net.  A minimum of at least one value is required.\n",
    "my_l1_ratios = [0, 0.1, 0.25, 0.5, 0.75, 0.9, 1]\n",
    "\n",
    "analysis = RENT.RENT_Classification(data=train_data, \n",
    "                                    target=train_labels, \n",
    "                                    feat_names=train_data.columns, \n",
    "                                    C=my_C_params, \n",
    "                                    l1_ratios=my_l1_ratios,\n",
    "                                    parameter_selection=True,\n",
    "                                    poly='OFF',\n",
    "                                    testsize_range=(0.25,0.25),\n",
    "                                    scoring='mcc',\n",
    "                                    method='logreg',\n",
    "                                    K=100,\n",
    "                                    verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "analysis.summary_criteria()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can play around with enet parameter setting...\n",
    "analysis.get_enet_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis.set_enet_params(1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis.get_enet_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis.set_enet_params(0.1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# contain only one element as we did paramter selection beforehand...\n",
    "analysis.get_enetParam_matrices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis.get_object_probabilities()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis.plot_object_probabilities(object_id=[293,332])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis.get_weight_distributions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis.summary_objects()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs_vars = analysis.selectFeatures(tau_1=0.9, tau_2=0.9, tau_3=0.975)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis.plot_selection_frequency()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis.get_runtime()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis.plot_object_PCA(group=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis.plot_object_PCA(group=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "analysis.plot_object_PCA(group='both')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predit test data\n",
    "\n",
    "# Import what is needed for prediction and evaluation of predictions from test set\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, matthews_corrcoef, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression as LR\n",
    "\n",
    "# Scale the data accordingly\n",
    "sc = StandardScaler()\n",
    "train_data_1 = sc.fit_transform(train_data.iloc[:, fs_vars])\n",
    "test_data_1 = sc.transform(test_data.iloc[:, fs_vars])\n",
    "\n",
    "# Train model with \n",
    "model = LR(penalty='none', max_iter=8000, solver=\"saga\", random_state=0).\\\n",
    "        fit(train_data_1, train_labels)\n",
    "\n",
    "# Print results\n",
    "print(\"f1 1: \", f1_score(test_labels, model.predict(test_data_1)))\n",
    "print(\"f1 0: \", f1_score(1 - test_labels, 1 - model.predict(test_data_1)))\n",
    "print(\"Accuracy: \", accuracy_score(test_labels, model.predict(test_data_1)))\n",
    "print(\"Matthews correlation coefficient: \", matthews_corrcoef(test_labels, model.predict(test_data_1)))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
